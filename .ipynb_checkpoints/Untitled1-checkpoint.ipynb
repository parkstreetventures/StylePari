{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112d16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EDA\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity,linear_kernel\n",
    "\n",
    "# other packages\n",
    "import nltk\n",
    "import string\n",
    "import ast\n",
    "import re\n",
    "import unidecode\n",
    "import unicodedata\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "import pickle \n",
    "import unidecode, ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ac5b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECIPES_PATH = \"./data/saree_data.csv\"\n",
    "PARSED_PATH = \"./data/test_parsed_new.csv\"\n",
    "TFIDF_ENCODING_PATH = \"./model/test_tfidf_encodings.pkl\"\n",
    "TFIDF_MODEL_PATH = \"./model/test_tfidf.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c340d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising stopwords for english\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "437e1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingredient_parser(ingreds):\n",
    "    \n",
    "    #showStatus(\"ingredient parser\")\n",
    "    measures = [ 'cup', 'c', 'p', 'pt',  'deciliter', 'decilitre',  'pound', 'lb', '#', 'ounce', 'oz', 'mg', 'milligram', 'milligramme', 'g', 'gram', 'gramme', 'kg', 'kilogram', 'kilogramme', 'x', 'of', 'mm', 'millimetre', 'millimeter', 'cm', 'centimeter', 'centimetre', 'm', 'meter', 'metre', 'inch', 'in', 'milli', 'centi', 'deci', 'hecto', 'kilo']\n",
    "    words_to_remove = ['(',')','.','\\'','with', 'matching', 'ba', 'gld', 'without', 'women', 'woman','shubh','self','fresh', 'trendz','oil', 'a', 'and',  'or',  'large', 'extra',  'free', 'small', 'from', 'higher', 'for', 'finely', 'freshly', 'to', 'organic', 'the', 'plain', 'plus' ]\n",
    "    # The ingredient list is now a string so we need to turn it back into a list. We use ast.literal_eval\n",
    "    if isinstance(ingreds, list):\n",
    "        ingredients = ingreds\n",
    "    else:\n",
    "        ingredients = ast.literal_eval(ingreds)\n",
    "    # We first get rid of all the punctuation. We make use of str.maketrans. It takes three input \n",
    "    # arguments 'x', 'y', 'z'. 'x' and 'y' must be equal-length strings and characters in 'x'\n",
    "    # are replaced by characters in 'y'. 'z' is a string (string.punctuation here) where each character\n",
    "    #  in the string is mapped to None. \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    ingred_list = []\n",
    "    for i in ingredients:\n",
    "        i.translate(translator)\n",
    "        # We split up with hyphens as well as spaces\n",
    "        items = re.split(' |-', i)\n",
    "        # Get rid of words containing non alphabet letters\n",
    "        items = [word for word in items if word.isalpha()]\n",
    "        # Turn everything to lowercase\n",
    "        items = [word.lower() for word in items]\n",
    "        \n",
    "        # remove stop words\n",
    "        items = [word for word in items if word not in stop_words]\n",
    "        # remove accents\n",
    "        items = [unidecode.unidecode(word) for word in items] #''.join((c for c in unicodedata.normalize('NFD', items) if unicodedata.category(c) != 'Mn'))\n",
    "        items = [unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore') for word in items]\n",
    "        \n",
    "        # Lemmatize words so we can compare words to measuring words\n",
    "        items = [lemmatizer.lemmatize(word) for word in items]\n",
    "        # Gets rid of measuring words/phrases, e.g. heaped teaspoon\n",
    "        items = [word for word in items if word not in measures]\n",
    "        # Get rid of common easy words\n",
    "        items = [word for word in items if word not in words_to_remove]\n",
    "        # remove all square brackets\n",
    "        #items = [remove_between_square_brackets(word) for word in items]\n",
    "        # remove all special characters\n",
    "        #items = [remove_special_characters(word) for word in items]\n",
    "        if items:\n",
    "            ingred_list.append(' '.join(items)) \n",
    "    ingred_list = \" \".join(ingred_list)\n",
    "    return ingred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c83389ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients</th>\n",
       "      <th>recipe_urls</th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>desc</th>\n",
       "      <th>ingredients_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(A, Govt., of, West, Bengal, Enterprises), Ha...</td>\n",
       "      <td>0.jpeg</td>\n",
       "      <td>saree tantuja bengal handloom</td>\n",
       "      <td>(A Govt. of West Bengal Enterprises) Handloom ...</td>\n",
       "      <td>west bengal handloom cotton ethnic wear tantuj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Women's, Silk, Saree, With, Blouse, Piece,sar...</td>\n",
       "      <td>1.jpeg</td>\n",
       "      <td>saree trilok fab</td>\n",
       "      <td>Women's Silk Saree With Blouse Piece</td>\n",
       "      <td>silk saree blouse trilok fab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Women's, Georgette, Net, Embroidered, Saree, ...</td>\n",
       "      <td>2.jpeg</td>\n",
       "      <td>saree nine sister</td>\n",
       "      <td>Women's Georgette Net Embroidered Saree with B...</td>\n",
       "      <td>georgette net embroidered saree blouse piece n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Women's, Crepe, Saree, with, Blouse, (GLE$CHI...</td>\n",
       "      <td>3.jpeg</td>\n",
       "      <td>saree gauri laxmi enterprise</td>\n",
       "      <td>Women's Crepe Saree with Blouse (GLE$CHICKOO C...</td>\n",
       "      <td>crepe saree blouse gauri laxmi enterprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Women's, Cotton, Blend, Digital, Butta, Print...</td>\n",
       "      <td>4.jpeg</td>\n",
       "      <td>saree sourbh</td>\n",
       "      <td>Women's Cotton Blend Digital Butta Printed Sar...</td>\n",
       "      <td>cotton blend digital butta printed saree blous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[GOGURL, Women's, Lycra, Cotton, Stretchable, ...</td>\n",
       "      <td>995.jpeg</td>\n",
       "      <td>blouse gogurl ‚äì you deserve the best</td>\n",
       "      <td>GOGURL Women's Lycra Cotton Stretchable Stitch...</td>\n",
       "      <td>gogurl lycra cotton stretchable stitched blous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[Women's, Multicolour, Sweet, Heart, Neckline,...</td>\n",
       "      <td>996.jpeg</td>\n",
       "      <td>blouse sumairatex</td>\n",
       "      <td>Women's Multicolour Sweet Heart Neckline Stone...</td>\n",
       "      <td>multicolour sweet heart neckline stone work ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[Round, Neck, Women, Blouse,blouse, mooldhani]</td>\n",
       "      <td>997.jpeg</td>\n",
       "      <td>blouse mooldhani</td>\n",
       "      <td>Round Neck Women Blouse</td>\n",
       "      <td>round neck mooldhani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[Women's, Navy, Blue, Phantom, Blouse, With, R...</td>\n",
       "      <td>998.jpeg</td>\n",
       "      <td>blouse fab dadu</td>\n",
       "      <td>Women's Navy Blue Phantom Blouse With Round Ne...</td>\n",
       "      <td>navy blue phantom blouse round neck bl fab dadu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[Black, Pure, Cotton, Handloom, Back-Open, Blo...</td>\n",
       "      <td>999.jpeg</td>\n",
       "      <td>blouse generic</td>\n",
       "      <td>Black Pure Cotton Handloom Back-Open Blouse Wi...</td>\n",
       "      <td>black pure cotton handloom back open blouse be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ingredients recipe_urls  \\\n",
       "0    [(A, Govt., of, West, Bengal, Enterprises), Ha...      0.jpeg   \n",
       "1    [Women's, Silk, Saree, With, Blouse, Piece,sar...      1.jpeg   \n",
       "2    [Women's, Georgette, Net, Embroidered, Saree, ...      2.jpeg   \n",
       "3    [Women's, Crepe, Saree, with, Blouse, (GLE$CHI...      3.jpeg   \n",
       "4    [Women's, Cotton, Blend, Digital, Butta, Print...      4.jpeg   \n",
       "..                                                 ...         ...   \n",
       "995  [GOGURL, Women's, Lycra, Cotton, Stretchable, ...    995.jpeg   \n",
       "996  [Women's, Multicolour, Sweet, Heart, Neckline,...    996.jpeg   \n",
       "997     [Round, Neck, Women, Blouse,blouse, mooldhani]    997.jpeg   \n",
       "998  [Women's, Navy, Blue, Phantom, Blouse, With, R...    998.jpeg   \n",
       "999  [Black, Pure, Cotton, Handloom, Back-Open, Blo...    999.jpeg   \n",
       "\n",
       "                                recipe_name  \\\n",
       "0             saree tantuja bengal handloom   \n",
       "1                          saree trilok fab   \n",
       "2                         saree nine sister   \n",
       "3              saree gauri laxmi enterprise   \n",
       "4                              saree sourbh   \n",
       "..                                      ...   \n",
       "995  blouse gogurl ‚äì you deserve the best   \n",
       "996                       blouse sumairatex   \n",
       "997                        blouse mooldhani   \n",
       "998                         blouse fab dadu   \n",
       "999                          blouse generic   \n",
       "\n",
       "                                                  desc  \\\n",
       "0    (A Govt. of West Bengal Enterprises) Handloom ...   \n",
       "1                 Women's Silk Saree With Blouse Piece   \n",
       "2    Women's Georgette Net Embroidered Saree with B...   \n",
       "3    Women's Crepe Saree with Blouse (GLE$CHICKOO C...   \n",
       "4    Women's Cotton Blend Digital Butta Printed Sar...   \n",
       "..                                                 ...   \n",
       "995  GOGURL Women's Lycra Cotton Stretchable Stitch...   \n",
       "996  Women's Multicolour Sweet Heart Neckline Stone...   \n",
       "997                            Round Neck Women Blouse   \n",
       "998  Women's Navy Blue Phantom Blouse With Round Ne...   \n",
       "999  Black Pure Cotton Handloom Back-Open Blouse Wi...   \n",
       "\n",
       "                                    ingredients_parsed  \n",
       "0    west bengal handloom cotton ethnic wear tantuj...  \n",
       "1                         silk saree blouse trilok fab  \n",
       "2    georgette net embroidered saree blouse piece n...  \n",
       "3            crepe saree blouse gauri laxmi enterprise  \n",
       "4    cotton blend digital butta printed saree blous...  \n",
       "..                                                 ...  \n",
       "995  gogurl lycra cotton stretchable stitched blous...  \n",
       "996  multicolour sweet heart neckline stone work ph...  \n",
       "997                               round neck mooldhani  \n",
       "998    navy blue phantom blouse round neck bl fab dadu  \n",
       "999  black pure cotton handloom back open blouse be...  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_df = pd.read_csv(RECIPES_PATH)\n",
    "recipe_df[\"desc\"] = recipe_df['ingredients']\n",
    "# change the way the sentence is arranged in the data\n",
    "recipe_df['ingredients'] = recipe_df['ingredients'].map(str) + ',' + recipe_df['recipe_name'].map(str)\n",
    "#recipe_df['ingredients'] = recipe_df['ingredients'].str.split()\n",
    "\n",
    "#df = [\"In monsoon it will rain\", \"rain rain come again\", \"sun is visible in rain summer. In the monsoon the sun is hidden by clouds\"]\n",
    "\n",
    "#recipe_df = pd.DataFrame(df,columns =['ingredients'])\n",
    "\n",
    "recipe_df['ingredients'] = recipe_df['ingredients'].str.split()\n",
    "\n",
    "\n",
    "recipe_df['ingredients_parsed'] = recipe_df['ingredients'].apply(lambda x: ingredient_parser(x))\n",
    "\n",
    "\n",
    "recipe_df\n",
    "#df = recipe_df[['recipe_name', 'desc', 'ingredients_parsed', 'ingredients', 'recipe_urls']]\n",
    "#df = recipe_df.dropna()\n",
    "\n",
    "# remove - Allrecipes.com from end of every recipe title \n",
    "#m = df.recipe_name.str.endswith('Recipe - Allrecipes.com')\n",
    "#df['recipe_name'].loc[m] = df.recipe_name.loc[m].str[:-23]        \n",
    "#df.to_csv(PARSED_PATH, index=False) #save the parsed file\n",
    "#save_data(df,PARSED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddfaf983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98aae023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1004)\t0.33703642546511575\n",
      "  (0, 1084)\t0.24310759697982354\n",
      "  (0, 289)\t0.26299884118667427\n",
      "  (0, 208)\t0.11880210535456126\n",
      "  (0, 374)\t0.4829254951845251\n",
      "  (0, 96)\t0.6177815400684534\n",
      "  (0, 1093)\t0.3593768890031947\n",
      "  (1, 299)\t0.48772353513424127\n",
      "  (1, 1030)\t0.8083833820985139\n",
      "  (1, 128)\t0.16807423930695073\n",
      "  (1, 860)\t0.1657001912486075\n",
      "  (1, 917)\t0.23007945915420408\n",
      "  (2, 923)\t0.5654629618424232\n",
      "  (2, 661)\t0.5654629618424232\n",
      "  (2, 726)\t0.2220582345478675\n",
      "  (2, 284)\t0.3180594293957211\n",
      "  (2, 655)\t0.3116585961044607\n",
      "  (2, 342)\t0.29264985430316076\n",
      "  (2, 128)\t0.11756767800100389\n",
      "  (2, 860)\t0.11590703494926015\n",
      "  (3, 287)\t0.38928392285177305\n",
      "  (3, 503)\t0.5554021090476613\n",
      "  (3, 337)\t0.5554021090476613\n",
      "  (3, 211)\t0.4494389062766843\n",
      "  (3, 128)\t0.12235113715603993\n",
      "  :\t:\n",
      "  (996, 1107)\t0.1813543262348211\n",
      "  (996, 128)\t0.08058648084560675\n",
      "  (996, 860)\t0.0794481970778556\n",
      "  (996, 917)\t0.11031609605703004\n",
      "  (997, 620)\t0.7845760250937758\n",
      "  (997, 820)\t0.46736922849186785\n",
      "  (997, 649)\t0.4074389096625005\n",
      "  (998, 117)\t0.4308093447043105\n",
      "  (998, 724)\t0.32243631059319044\n",
      "  (998, 820)\t0.27767984057670997\n",
      "  (998, 649)\t0.24207321445810645\n",
      "  (998, 646)\t0.41774995521002006\n",
      "  (998, 217)\t0.3802595121673093\n",
      "  (998, 129)\t0.35502682506207733\n",
      "  (998, 299)\t0.3403259134296613\n",
      "  (998, 128)\t0.11727959570454134\n",
      "  (999, 93)\t0.5329020414958746\n",
      "  (999, 683)\t0.4069994440837359\n",
      "  (999, 66)\t0.3748494295910727\n",
      "  (999, 118)\t0.33540526038091173\n",
      "  (999, 763)\t0.2951749374485472\n",
      "  (999, 340)\t0.26046325307442336\n",
      "  (999, 128)\t0.11079780613133025\n",
      "  (999, 208)\t0.15924284251572374\n",
      "  (999, 374)\t0.3236576841251436\n",
      "['aagam', 'aaghnya', 'aahiri', 'aangel', 'aaradhya', 'aarrah', 'abhi', 'ac', 'accessory', 'ada', 'add', 'advi', 'affair', 'age', 'ahalyaa', 'aika', 'air', 'aishwarya', 'ajs', 'akhilam', 'aldwych', 'ali', 'almaari', 'aloff', 'alternative', 'amaira', 'ambey', 'ambica', 'amiira', 'amrutam', 'anand', 'anaya', 'angel', 'anik', 'animal', 'anirban', 'anjaneya', 'ank', 'anks', 'anni', 'apnisha', 'applecreation', 'areum', 'arkee', 'arriva', 'arrow', 'art', 'artena', 'artificial', 'aruna', 'asavari', 'ashvmegh', 'assamese', 'asscesory', 'assorted', 'assure', 'asthlaxmi', 'athreya', 'attached', 'attractive', 'auriglam', 'avantika', 'avik', 'avr', 'ayaan', 'baby', 'back', 'backopen', 'bagru', 'baluchari', 'bamboo', 'banarasi', 'band', 'bandej', 'bandhani', 'bandhej', 'bandidhari', 'bangalori', 'banglori', 'based', 'basic', 'bastralaya', 'bathik', 'batik', 'bawri', 'bb', 'beautiful', 'beautifully', 'begampuri', 'beglory', 'begum', 'beige', 'belguan', 'bell', 'bella', 'belly', 'bengal', 'bengali', 'benglori', 'benglory', 'bermondsey', 'best', 'better', 'betterbuy', 'beuniv', 'bh', 'bhagalpuri', 'bhakarwadi', 'bharatanatyam', 'bhimashankar', 'bhulahi', 'bhuwal', 'bidesh', 'bieth', 'big', 'bigmart', 'biyu', 'bl', 'black', 'blause', 'blazze', 'blck', 'blend', 'blended', 'blissta', 'block', 'blockmoda', 'blous', 'blouse', 'blue', 'boat', 'boatneck', 'bolly', 'bollywood', 'booti', 'border', 'bordered', 'borderless', 'bottle', 'boutique', 'brand', 'brasso', 'bright', 'broad', 'brocad', 'brocade', 'brother', 'brown', 'bsc', 'bulbul', 'bustier', 'buta', 'butta', 'butterfly', 'button', 'buy', 'buyonn', 'buyzone', 'cap', 'caramel', 'casual', 'cbros', 'cdpl', 'centre', 'chador', 'chain', 'chandana', 'chanderi', 'charcoal', 'check', 'checked', 'checkered', 'chek', 'chennai', 'chex', 'chiffli', 'chiffon', 'chikankari', 'chiku', 'chinon', 'chip', 'choice', 'choli', 'cholis', 'city', 'clickedia', 'closure', 'cloth', 'clothing', 'cloud', 'clovia', 'coding', 'collar', 'collection', 'color', 'colour', 'combo', 'comfort', 'commerce', 'common', 'complimentary', 'concepta', 'contrast', 'copper', 'corp', 'cotfeel', 'cottage', 'cottan', 'cotton', 'cream', 'creation', 'crepe', 'creta', 'crimson', 'crop', 'curate', 'cut', 'dadu', 'daily', 'dark', 'datta', 'db', 'deal', 'dealsure', 'decor', 'deep', 'denim', 'deserve', 'desginer', 'desh', 'desigirl', 'design', 'designer', 'desimiss', 'desine', 'desiwear', 'destiny', 'dev', 'dhadi', 'dhakai', 'dharmavaram', 'dhori', 'dhoti', 'dhruvi', 'diamond', 'diara', 'digital', 'digitofab', 'ditya', 'divastri', 'divya', 'dn', 'dobby', 'dolfin', 'dolly', 'doresuza', 'doria', 'dot', 'double', 'dpk', 'drapme', 'dresser', 'drg', 'drop', 'dubai', 'dulari', 'dum', 'dupion', 'dusty', 'dutta', 'dwiza', 'dying', 'ecommerce', 'eesha', 'eeshagupta', 'eight', 'ekta', 'elbow', 'elephant', 'embellished', 'embridery', 'embriodered', 'embrodery', 'embroider', 'embroidered', 'embroidery', 'embroidey', 'enterprise', 'epic', 'ethnic', 'ethnicjunction', 'ethnicjuntion', 'evanta', 'everwey', 'every', 'exonic', 'export', 'express', 'eye', 'fab', 'fabpandora', 'fabric', 'fabwomen', 'face', 'factory', 'fancy', 'fantam', 'fashdeal', 'fashion', 'fashionbonanzamart', 'faux', 'femmibella', 'festival', 'festive', 'ffashion', 'fine', 'firstrack', 'fish', 'fit', 'five', 'flared', 'floral', 'flossy', 'flower', 'foil', 'foilage', 'foiled', 'foliarry', 'formal', 'fressia', 'frill', 'front', 'full', 'fully', 'fur', 'gadwal', 'gajanan', 'gauri', 'ge', 'geeta', 'generic', 'geometric', 'georgette', 'gift', 'girl', 'gk', 'glamourholic', 'glamourous', 'go', 'gogurl', 'gold', 'golden', 'gomore', 'goodluck', 'gorgeous', 'gorgone', 'gosriki', 'gotta', 'gp', 'grand', 'graphic', 'great', 'green', 'grey', 'gupta', 'gurjari', 'guru', 'haico', 'haider', 'half', 'halter', 'hand', 'handcrafted', 'handicraft', 'handloom', 'handmade', 'handwork', 'handwoven', 'harikrupex', 'harsukhi', 'haviya', 'hc', 'heart', 'heavy', 'heht', 'hevay', 'hevy', 'hf', 'high', 'highneck', 'himalay', 'hitarth', 'holland', 'holyday', 'hook', 'house', 'hum', 'humairah', 'hutah', 'hwt', 'id', 'ikat', 'ikkat', 'ilkal', 'impex', 'inaya', 'india', 'indigo', 'industry', 'inner', 'intrigue', 'isha', 'ishin', 'iswr', 'italian', 'jaal', 'jaam', 'jacket', 'jacquard', 'jagasree', 'jainithish', 'jaipur', 'jaipuri', 'jaketa', 'jamdani', 'janasya', 'janvisales', 'japan', 'jari', 'jay', 'jelite', 'jequard', 'jerrica', 'jevi', 'jimplei', 'jisb', 'jivika', 'jkg', 'joy', 'junction', 'jute', 'kabir', 'kach', 'kakinada', 'kalamkari', 'kalkee', 'kamal', 'kanchan', 'kanchi', 'kanchipuram', 'kanchivaram', 'kanjivaram', 'kanjivarm', 'kanjiwaram', 'kannchi', 'kanta', 'kantha', 'karmi', 'kart', 'kasavu', 'kashida', 'kashmiri', 'kashvi', 'katan', 'kayra', 'keerat', 'kerala', 'keri', 'keyu', 'khadi', 'khan', 'khatli', 'khes', 'khun', 'kiaaron', 'king', 'kingry', 'klara', 'knitted', 'knitting', 'kora', 'kota', 'koti', 'krishav', 'krishna', 'krishnvatika', 'ksut', 'kt', 'kuber', 'kullu', 'kulu', 'kundan', 'kupinda', 'kuppadam', 'kurta', 'laavaan', 'lace', 'lacossi', 'lady', 'lahenga', 'lash', 'latest', 'latkan', 'laxmi', 'laxmipati', 'laycra', 'le', 'leelavati', 'leeza', 'lehanga', 'lehariya', 'lehenga', 'leheriya', 'lehnga', 'length', 'lenixa', 'lensta', 'lichi', 'life', 'lifestyle', 'light', 'likki', 'lime', 'line', 'linen', 'linfa', 'linisa', 'lionize', 'litchy', 'llajja', 'lnc', 'long', 'look', 'lookline', 'lookstar', 'loom', 'lotus', 'louis', 'lounge', 'lp', 'ltd', 'lucknowi', 'luxe', 'luxowear', 'lycra', 'lyrca', 'lyrn', 'maa', 'made', 'madhu', 'madhubala', 'madhubani', 'madhusri', 'madras', 'madurai', 'mafia', 'magenta', 'maggam', 'magic', 'mahadevfab', 'mahakal', 'mahant', 'mahatma', 'maheshwari', 'mahi', 'malai', 'malbari', 'malgudi', 'mall', 'malmal', 'mandia', 'mangalagiri', 'mango', 'manipuri', 'manisha', 'manjula', 'manohari', 'mansi', 'mantra', 'marble', 'market', 'maroon', 'marriage', 'mart', 'maruthi', 'maruti', 'master', 'material', 'matka', 'matty', 'may', 'meena', 'mehendi', 'mekhela', 'mekhla', 'meldi', 'memore', 'men', 'meram', 'mercerised', 'mesmore', 'mhd', 'mijh', 'mill', 'mimosa', 'minakari', 'mint', 'minute', 'miraan', 'mirchi', 'mirraw', 'mirror', 'mj', 'mk', 'mobile', 'modal', 'molmol', 'monikafashion', 'monira', 'mooga', 'mooldhani', 'mor', 'morvi', 'moti', 'muhenera', 'muktidata', 'mul', 'mulmul', 'multi', 'multicolor', 'multicolour', 'multicoloured', 'mundu', 'munga', 'muslin', 'mustardnd', 'musterd', 'mustered', 'mutlicolor', 'mysore', 'mysure', 'naitri', 'nakshatra', 'narayanpet', 'nath', 'navarang', 'navy', 'naz', 'nd', 'neck', 'neckless', 'neckline', 'neelghar', 'nehru', 'nena', 'net', 'nevy', 'new', 'nikhilam', 'nikxtex', 'nilkanth', 'nine', 'nirja', 'nirmla', 'nishtha', 'nityanta', 'nivah', 'niza', 'nk', 'non', 'noyonchuri', 'nplash', 'nvy', 'nx', 'nylon', 'ocean', 'odisha', 'offer', 'olive', 'one', 'ong', 'online', 'opara', 'open', 'option', 'orange', 'organja', 'organza', 'orgenza', 'original', 'osp', 'pack', 'packing', 'pad', 'padded', 'pahel', 'paisley', 'paithani', 'pal', 'pallu', 'pandadi', 'paper', 'parampara', 'pari', 'parin', 'parishkaar', 'parmeen', 'paroot', 'parrot', 'party', 'patta', 'pattern', 'pattu', 'pavechas', 'pch', 'pcn', 'pd', 'peacock', 'pearl', 'pemal', 'perfect', 'perfectblue', 'perrot', 'phanto', 'phantom', 'pice', 'piece', 'pink', 'pinkish', 'pinkloom', 'piping', 'pisara', 'pista', 'pitch', 'pitton', 'pkyc', 'plastic', 'pochampally', 'pogo', 'polka', 'poly', 'polycotton', 'polyester', 'pom', 'pompom', 'pooja', 'powerloom', 'pramukh', 'premium', 'present', 'prettified', 'pretty', 'primium', 'princess', 'print', 'printed', 'priyal', 'priyanka', 'priyannsh', 'priyansh', 'prutha', 'puff', 'pujia', 'pure', 'purple', 'purplefly', 'purvi', 'pv', 'pwcs', 'quality', 'radha', 'radiance', 'rajasthani', 'rajeshwar', 'rajjo', 'rajlaxmi', 'rajnandini', 'ram', 'rama', 'rang', 'rani', 'raw', 'rayon', 'razeena', 'rb', 'reach', 'ready', 'readymade', 'real', 'reboot', 'red', 'reeva', 'refof', 'regolith', 'regular', 'rene', 'rensil', 'replica', 'resham', 'retail', 'reversal', 'rf', 'rich', 'riddhi', 'rinkoo', 'riti', 'ritmo', 'rivana', 'riwaz', 'rjkart', 'rkbk', 'roaroop', 'rob', 'robyn', 'rola', 'romano', 'roopaima', 'root', 'rose', 'rosebud', 'round', 'royal', 'rudra', 'ruffle', 'runaya', 'rund', 'running', 'rupee', 'rust', 'rutva', 'rv', 'ry', 'saahiba', 'saara', 'saarvi', 'sachet', 'sachetimpex', 'sadi', 'sador', 'saees', 'sahajanand', 'saheli', 'sahib', 'saini', 'sajan', 'sale', 'saln', 'salwar', 'sambalpuri', 'samudra', 'sana', 'sanganeri', 'sanidhya', 'sanmati', 'sanskar', 'sansrukti', 'sapta', 'saptashri', 'saravanabava', 'sare', 'saree', 'sari', 'sat', 'satin', 'satrani', 'satyam', 'savi', 'sblcw', 'scarlet', 'scoop', 'sd', 'sdew', 'season', 'selected', 'seller', 'selly', 'selrina', 'semi', 'separate', 'sequance', 'sequence', 'sequin', 'sequnce', 'serraw', 'set', 'sexy', 'shaded', 'shailaja', 'shaily', 'shakti', 'shantipur', 'shape', 'shapewear', 'shg', 'shimmer', 'shino', 'shiny', 'shipra', 'shiv', 'shivanya', 'shivay', 'shivoham', 'shiya', 'shop', 'shoplex', 'shopping', 'short', 'showroom', 'shree', 'shreeji', 'shreejiih', 'shreya', 'shringaar', 'shubham', 'shubhsarini', 'shyamansh', 'side', 'silk', 'silknest', 'sillk', 'silver', 'silverstar', 'siril', 'sister', 'size', 'skirt', 'sky', 'sleeve', 'sleeveless', 'sleevesless', 'sleevs', 'slightly', 'slik', 'slim', 'slub', 'sneh', 'snowin', 'soch', 'soft', 'soham', 'solid', 'son', 'sourbh', 'south', 'sp', 'spagetti', 'spangel', 'sparkle', 'spham', 'spiaty', 'spreading', 'square', 'squareneck', 'sr', 'sretan', 'sri', 'stand', 'star', 'step', 'stiched', 'stitch', 'stitched', 'stone', 'store', 'strech', 'strechable', 'stretch', 'stretchable', 'string', 'stripe', 'striped', 'studio', 'styalish', 'styel', 'style', 'stylehut', 'stylish', 'sugathari', 'suit', 'sukanya', 'sum', 'sumaira', 'sumairatex', 'summer', 'sumshy', 'sunderani', 'sungudi', 'supplier', 'supujit', 'surat', 'suvasana', 'svb', 'swami', 'swarna', 'sweater', 'sweet', 'sweetheart', 'sye', 'synthetic', 'taffata', 'taksh', 'tanchoi', 'tangail', 'tant', 'tantuja', 'tapeta', 'tassel', 'tdc', 'temple', 'tex', 'textile', 'texture', 'thecrownlady', 'thick', 'thread', 'tilak', 'tilism', 'tinsie', 'tissue', 'tissui', 'top', 'toshika', 'traditional', 'trancereble', 'transparent', 'traveller', 'tredilla', 'trend', 'trending', 'trendy', 'trilok', 'tropical', 'tulasi', 'turquoise', 'tussar', 'txt', 'ty', 'typ', 'type', 'ultimate', 'umasaree', 'un', 'unico', 'uniform', 'unique', 'unnati', 'unstich', 'unstiched', 'unstitched', 'untitched', 'upcoming', 'uppada', 'usable', 'using', 'usk', 'vaamsi', 'vaghasiya', 'vaividhyam', 'vamas', 'vami', 'vardha', 'varni', 'vastra', 'vastranand', 'vbuyz', 'vebnor', 'velvet', 'venisa', 'venkatagiri', 'vicharan', 'vichitra', 'vihu', 'villagius', 'vimla', 'vinayak', 'vipul', 'vision', 'viva', 'vivan', 'vivanfab', 'vj', 'ware', 'warm', 'water', 'wear', 'wearheavy', 'weave', 'weaved', 'weaver', 'weaving', 'webbuy', 'wedding', 'weight', 'west', 'white', 'whte', 'wiaght', 'widehaven', 'widehavenfashion', 'win', 'winter', 'winza', 'womanista', 'wooden', 'woodentant', 'wool', 'woollen', 'work', 'worked', 'workeed', 'world', 'woven', 'wrinklefree', 'xaya', 'xomantic', 'yagnaseni', 'yard', 'yashika', 'yazu', 'yellow', 'yellowv', 'yesasri', 'yoella', 'yogeshwar', 'za', 'zahira', 'zardosi', 'zari', 'zipper']\n",
      "     aagam  aaghnya  aahiri  aangel  aaradhya  aarrah  abhi   ac  accessory  \\\n",
      "0      0.0      0.0     0.0     0.0       0.0     0.0   0.0  0.0        0.0   \n",
      "1      0.0      0.0     0.0     0.0       0.0     0.0   0.0  0.0        0.0   \n",
      "2      0.0      0.0     0.0     0.0       0.0     0.0   0.0  0.0        0.0   \n",
      "3      0.0      0.0     0.0     0.0       0.0     0.0   0.0  0.0        0.0   \n",
      "4      0.0      0.0     0.0     0.0       0.0     0.0   0.0  0.0        0.0   \n",
      "..     ...      ...     ...     ...       ...     ...   ...  ...        ...   \n",
      "995    0.0      0.0     0.0     0.0       0.0     0.0   0.0  0.0        0.0   \n",
      "996    0.0      0.0     0.0     0.0       0.0     0.0   0.0  0.0        0.0   \n",
      "997    0.0      0.0     0.0     0.0       0.0     0.0   0.0  0.0        0.0   \n",
      "998    0.0      0.0     0.0     0.0       0.0     0.0   0.0  0.0        0.0   \n",
      "999    0.0      0.0     0.0     0.0       0.0     0.0   0.0  0.0        0.0   \n",
      "\n",
      "     ada  ...  yellow  yellowv  yesasri  yoella  yogeshwar   za  zahira  \\\n",
      "0    0.0  ...     0.0      0.0      0.0     0.0        0.0  0.0     0.0   \n",
      "1    0.0  ...     0.0      0.0      0.0     0.0        0.0  0.0     0.0   \n",
      "2    0.0  ...     0.0      0.0      0.0     0.0        0.0  0.0     0.0   \n",
      "3    0.0  ...     0.0      0.0      0.0     0.0        0.0  0.0     0.0   \n",
      "4    0.0  ...     0.0      0.0      0.0     0.0        0.0  0.0     0.0   \n",
      "..   ...  ...     ...      ...      ...     ...        ...  ...     ...   \n",
      "995  0.0  ...     0.0      0.0      0.0     0.0        0.0  0.0     0.0   \n",
      "996  0.0  ...     0.0      0.0      0.0     0.0        0.0  0.0     0.0   \n",
      "997  0.0  ...     0.0      0.0      0.0     0.0        0.0  0.0     0.0   \n",
      "998  0.0  ...     0.0      0.0      0.0     0.0        0.0  0.0     0.0   \n",
      "999  0.0  ...     0.0      0.0      0.0     0.0        0.0  0.0     0.0   \n",
      "\n",
      "     zardosi  zari  zipper  \n",
      "0        0.0   0.0     0.0  \n",
      "1        0.0   0.0     0.0  \n",
      "2        0.0   0.0     0.0  \n",
      "3        0.0   0.0     0.0  \n",
      "4        0.0   0.0     0.0  \n",
      "..       ...   ...     ...  \n",
      "995      0.0   0.0     0.0  \n",
      "996      0.0   0.0     0.0  \n",
      "997      0.0   0.0     0.0  \n",
      "998      0.0   0.0     0.0  \n",
      "999      0.0   0.0     0.0  \n",
      "\n",
      "[1000 rows x 1129 columns]\n"
     ]
    }
   ],
   "source": [
    "#Initialising Tfidf Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "#Fitting the Vectorizer to the list\n",
    "X = vectorizer.fit_transform(recipe_df['ingredients_parsed'])\n",
    "print(X)\n",
    "#Printing the feature names\n",
    "print(vectorizer.get_feature_names())\n",
    "matrix = X.todense()\n",
    "tfidf_list = matrix.tolist()\n",
    "tfidf_df = pd.DataFrame(tfidf_list, columns = vectorizer.get_feature_names())\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82c0adab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x1129 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7653 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "news_articles_temp = recipe_df.copy()\n",
    "headline_vectorizer = CountVectorizer()\n",
    "headline_features   = headline_vectorizer.fit_transform(news_articles_temp['ingredients_parsed'])\n",
    "headline_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aca4d4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Queried article details ==============================\n",
      "headline :  saree trilok fab\n",
      "\n",
      " ========================= Recommended articles :  =======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1      Women's kanchipuram Silk Saree With Blouse Piece\n",
       "2                          Silk Saree with Blouse Piece\n",
       "3                   Litchy Silk Saree With Blouse Piece\n",
       "4                          Silk Saree with Blouse Piece\n",
       "5         Women's Banarasi Silk Saree With Blouse Piece\n",
       "6           Women's Cotton Silk Saree with blouse peace\n",
       "7              Women's Art Silk Saree With Blouse Piece\n",
       "8     Women's Art Silk Saree With Blouse Piece(Free ...\n",
       "9                      Art Silk Saree with Blouse Piece\n",
       "10                     Art Silk Saree with Blouse Piece\n",
       "Name: desc, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bag of words model\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def bag_of_words_based_model(row_index, num_similar_items):\n",
    "    couple_dist = pairwise_distances(headline_features,headline_features[row_index])\n",
    "    indices = np.argsort(couple_dist.ravel())[0:num_similar_items]\n",
    "    df = pd.DataFrame({'desc':news_articles_temp['desc'][indices].values,\n",
    "               'headline':news_articles_temp['recipe_name'][indices].values,\n",
    "                'Euclidean similarity with the queried article': couple_dist[indices].ravel()})\n",
    "    print(\"=\"*30,\"Queried article details\",\"=\"*30)\n",
    "    print('headline : ',news_articles_temp['recipe_name'][indices[0]])\n",
    "    print(\"\\n\",\"=\"*25,\"Recommended articles : \",\"=\"*23)\n",
    "    #print(df.head(5))\n",
    "    return df.iloc[1:,0]\n",
    "    #return df.iloc[1:,]\n",
    "\n",
    "bag_of_words_based_model(1, 11) # Change the row index for any other queried article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa95a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
