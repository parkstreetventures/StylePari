{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import nltk\n",
    "import string\n",
    "import ast\n",
    "import re\n",
    "import unidecode\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "import pickle \n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import unidecode, ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to all files\n",
    "DATA_PATH = \"./data/df_recipes.csv\"\n",
    "PARSED_PATH = \"./data/df_parsed_new.csv\"\n",
    "TFIDF_ENCODING_PATH = \"./model/tfidf_encodings.pkl\"\n",
    "TFIDF_MODEL_PATH = \"./model/tfidf.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weigths and measures are words that will not add value to the model. I got these standard words from \n",
    "# https://en.wikibooks.org/wiki/Cookbook:Units_of_measurement\n",
    "\n",
    "# # We lemmatize the words to reduce them to their smallest form (lemmas). \n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# measures = [lemmatizer.lemmatize(m) for m in measures]\n",
    "# words_to_remove = [lemmatizer.lemmatize(m) for m in words_to_remove]\n",
    "\n",
    "def ingredient_parser(ingreds):\n",
    "    '''\n",
    "    \n",
    "    This function takes in a list (but it is a string as it comes from pandas dataframe) of \n",
    "       ingredients and performs some preprocessing. \n",
    "       For example:\n",
    "       input = '['1 x 1.6kg whole duck', '2 heaped teaspoons Chinese five-spice powder', '1 clementine',\n",
    "                 '6 fresh bay leaves', 'GRAVY', '', '1 bulb of garlic', '2 carrots', '2 red onions', \n",
    "                 '3 tablespoons plain flour', '100 ml Marsala', '1 litre organic chicken stock']'\n",
    "       \n",
    "       output = ['duck', 'chinese five spice powder', 'clementine', 'fresh bay leaf', 'gravy', 'garlic',\n",
    "                 'carrot', 'red onion', 'plain flour', 'marsala', 'organic chicken stock']\n",
    "    '''\n",
    "    measures = ['teaspoon', 't', 'tsp.', 'tablespoon', 'T', 'tbl.', 'tb', 'tbsp.', 'fluid ounce', 'fl oz', 'gill', 'cup', 'c', 'pint', 'p', 'pt', 'fl pt', 'quart', 'q', 'qt', 'fl qt', 'gallon', 'g', 'gal', 'ml', 'milliliter', 'millilitre', 'cc', 'mL', 'l', 'liter', 'litre', 'L', 'dl', 'deciliter', 'decilitre', 'dL', 'bulb', 'level', 'heaped', 'rounded', 'whole', 'pinch', 'medium', 'slice', 'pound', 'lb', '#', 'ounce', 'oz', 'mg', 'milligram', 'milligramme', 'g', 'gram', 'gramme', 'kg', 'kilogram', 'kilogramme', 'x', 'of', 'mm', 'millimetre', 'millimeter', 'cm', 'centimeter', 'centimetre', 'm', 'meter', 'metre', 'inch', 'in', 'milli', 'centi', 'deci', 'hecto', 'kilo']\n",
    "    words_to_remove = ['fresh', 'oil', 'a', 'red', 'bunch', 'and', 'clove', 'or', 'leaf', 'chilli', 'large', 'extra', 'sprig', 'ground', 'handful', 'free', 'small', 'pepper', 'virgin', 'range', 'from', 'dried', 'sustainable', 'black', 'peeled', 'higher', 'welfare', 'seed', 'for', 'finely', 'freshly', 'sea', 'quality', 'white', 'ripe', 'few', 'piece', 'source', 'to', 'organic', 'flat', 'smoked', 'ginger', 'sliced', 'green', 'picked', 'the', 'stick', 'plain', 'plus', 'mixed', 'mint', 'bay', 'basil', 'your', 'cumin', 'optional', 'fennel', 'serve', 'mustard', 'unsalted', 'baby', 'paprika', 'fat', 'ask', 'natural', 'skin', 'roughly', 'into', 'such', 'cut', 'good', 'brown', 'grated', 'trimmed', 'oregano', 'powder', 'yellow', 'dusting', 'knob', 'frozen', 'on', 'deseeded', 'low', 'runny', 'balsamic', 'cooked', 'streaky', 'nutmeg', 'sage', 'rasher', 'zest', 'pin', 'groundnut', 'breadcrumb', 'turmeric', 'halved', 'grating', 'stalk', 'light', 'tinned', 'dry', 'soft', 'rocket', 'bone', 'colour', 'washed', 'skinless', 'leftover', 'splash', 'removed', 'dijon', 'thick', 'big', 'hot', 'drained', 'sized', 'chestnut', 'watercress', 'fishmonger', 'english', 'dill', 'caper', 'raw', 'worcestershire', 'flake', 'cider', 'cayenne', 'tbsp', 'leg', 'pine', 'wild', 'if', 'fine', 'herb', 'almond', 'shoulder', 'cube', 'dressing', 'with', 'chunk', 'spice', 'thumb', 'garam', 'new', 'little', 'punnet', 'peppercorn', 'shelled', 'saffron', 'other''chopped', 'salt', 'olive', 'taste', 'can', 'sauce', 'water', 'diced', 'package', 'italian', 'shredded', 'divided', 'parsley', 'vinegar', 'all', 'purpose', 'crushed', 'juice', 'more', 'coriander', 'bell', 'needed', 'thinly', 'boneless', 'half', 'thyme', 'cubed', 'cinnamon', 'cilantro', 'jar', 'seasoning', 'rosemary', 'extract', 'sweet', 'baking', 'beaten', 'heavy', 'seeded', 'tin', 'vanilla', 'uncooked', 'crumb', 'style', 'thin', 'nut', 'coarsely', 'spring', 'chili', 'cornstarch', 'strip', 'cardamom', 'rinsed', 'honey', 'cherry', 'root', 'quartered', 'head', 'softened', 'container', 'crumbled', 'frying', 'lean', 'cooking', 'roasted', 'warm', 'whipping', 'thawed', 'corn', 'pitted', 'sun', 'kosher', 'bite', 'toasted', 'lasagna', 'split', 'melted', 'degree', 'lengthwise', 'romano', 'packed', 'pod', 'anchovy', 'rom', 'prepared', 'juiced', 'fluid', 'floret', 'room', 'active', 'seasoned', 'mix', 'deveined', 'lightly', 'anise', 'thai', 'size', 'unsweetened', 'torn', 'wedge', 'sour', 'basmati', 'marinara', 'dark', 'temperature', 'garnish', 'bouillon', 'loaf', 'shell', 'reggiano', 'canola', 'parmigiano', 'round', 'canned', 'ghee', 'crust', 'long', 'broken', 'ketchup', 'bulk', 'cleaned', 'condensed', 'sherry', 'provolone', 'cold', 'soda', 'cottage', 'spray', 'tamarind', 'pecorino', 'shortening', 'part', 'bottle', 'sodium', 'cocoa', 'grain', 'french', 'roast', 'stem', 'link', 'firm', 'asafoetida', 'mild', 'dash', 'boiling']\n",
    "    # The ingredient list is now a string so we need to turn it back into a list. We use ast.literal_eval\n",
    "    if isinstance(ingreds, list):\n",
    "        ingredients = ingreds\n",
    "    else:\n",
    "        ingredients = ast.literal_eval(ingreds)\n",
    "    # We first get rid of all the punctuation. We make use of str.maketrans. It takes three input \n",
    "    # arguments 'x', 'y', 'z'. 'x' and 'y' must be equal-length strings and characters in 'x'\n",
    "    # are replaced by characters in 'y'. 'z' is a string (string.punctuation here) where each character\n",
    "    #  in the string is mapped to None. \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    ingred_list = []\n",
    "    for i in ingredients:\n",
    "        i.translate(translator)\n",
    "        # We split up with hyphens as well as spaces\n",
    "        items = re.split(' |-', i)\n",
    "        # Get rid of words containing non alphabet letters\n",
    "        items = [word for word in items if word.isalpha()]\n",
    "        # Turn everything to lowercase\n",
    "        items = [word.lower() for word in items]\n",
    "        # remove accents\n",
    "        items = [unidecode.unidecode(word) for word in items] #''.join((c for c in unicodedata.normalize('NFD', items) if unicodedata.category(c) != 'Mn'))\n",
    "        # Lemmatize words so we can compare words to measuring words\n",
    "        items = [lemmatizer.lemmatize(word) for word in items]\n",
    "        # Gets rid of measuring words/phrases, e.g. heaped teaspoon\n",
    "        items = [word for word in items if word not in measures]\n",
    "        # Get rid of common easy words\n",
    "        items = [word for word in items if word not in words_to_remove]\n",
    "        if items:\n",
    "            ingred_list.append(' '.join(items)) \n",
    "    ingred_list = \" \".join(ingred_list)\n",
    "    return ingred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommendation system\n",
    "\n",
    "# Top-N recomendations order by score\n",
    "def get_recommendations(N, scores):\n",
    "    # load in recipe dataset \n",
    "    df_recipes = pd.read_csv(PARSED_PATH)\n",
    "    # order the scores with and filter to get the highest N scores\n",
    "    top = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:N]\n",
    "    # create dataframe to load in recommendations \n",
    "    # added \"dtype=\" to fix a pandas dataframe error\n",
    "    recommendation = pd.DataFrame(columns = ['recipe', 'ingredients', 'score', 'url'], dtype=object)\n",
    "    #print (recommendation)\n",
    "    count = 0\n",
    "    for i in top:\n",
    "        recommendation.at[count, 'recipe'] = title_parser(df_recipes['recipe_name'][i])\n",
    "        recommendation.at[count, 'ingredients'] = ingredient_parser_final(df_recipes['ingredients'][i])\n",
    "        recommendation.at[count, 'url'] = df_recipes['recipe_urls'][i]\n",
    "        recommendation.at[count, 'score'] = \"{:.3f}\".format(float(scores[i])) #error here?\n",
    "        count += 1\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neaten the ingredients being outputted \n",
    "def ingredient_parser_final(ingredient):\n",
    "    if isinstance(ingredient, list):\n",
    "        ingredients = ingredient\n",
    "    else:\n",
    "        ingredients = ast.literal_eval(ingredient)\n",
    "    \n",
    "    ingredients = ','.join(ingredients)\n",
    "    ingredients = unidecode.unidecode(ingredients)\n",
    "    return ingredients\n",
    "\n",
    "def title_parser(title):\n",
    "    title = unidecode.unidecode(title)\n",
    "    return title \n",
    "\n",
    "def RecSys(ingredients, N=5):\n",
    "    \"\"\"\n",
    "    The reccomendation system takes in a list of ingredients and returns a list of top 5 \n",
    "    recipes based of of cosine similarity. \n",
    "    :param ingredients: a list of ingredients\n",
    "    :param N: the number of reccomendations returned \n",
    "    :return: top 5 reccomendations for cooking recipes\n",
    "    \"\"\"\n",
    "\n",
    "    # load in tdidf model and encodings \n",
    "    with open(TFIDF_ENCODING_PATH, 'rb') as f:\n",
    "        tfidf_encodings = pickle.load(f)\n",
    "\n",
    "    with open(TFIDF_MODEL_PATH, \"rb\") as f:\n",
    "        tfidf = pickle.load(f)\n",
    "\n",
    "    # parse the ingredients using my ingredient_parser \n",
    "    try: \n",
    "        ingredients_parsed = ingredient_parser(ingredients)\n",
    "    except:\n",
    "        ingredients_parsed = ingredient_parser([ingredients])\n",
    "    \n",
    "    # use our pretrained tfidf model to encode our input ingredients\n",
    "    ingredients_tfidf = tfidf.transform([ingredients_parsed])\n",
    "\n",
    "    # calculate cosine similarity between actual recipe ingreds and test ingreds\n",
    "    cos_sim = map(lambda x: cosine_similarity(ingredients_tfidf, x), tfidf_encodings)\n",
    "    scores = list(cos_sim)\n",
    "    #print(scores)\n",
    "\n",
    "    # Filter top N recommendations \n",
    "    recommendations = get_recommendations(N, scores)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses the recipes into words\n",
    "recipe_df = pd.read_csv(DATA_PATH)\n",
    "recipe_df['ingredients_parsed'] = recipe_df['ingredients'].apply(lambda x: ingredient_parser(x))\n",
    "\n",
    "df = recipe_df[['recipe_name', 'ingredients_parsed', 'ingredients', 'recipe_urls']]\n",
    "df = recipe_df.dropna()\n",
    "\n",
    "# remove - Allrecipes.com from end of every recipe title \n",
    "m = df.recipe_name.str.endswith('Recipe - Allrecipes.com')\n",
    "df['recipe_name'].loc[m] = df.recipe_name.loc[m].str[:-23]        \n",
    "df.to_csv(PARSED_PATH, index=False) #save the parsed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in parsed recipe dataset \n",
    "df_recipes = pd.read_csv(PARSED_PATH)\n",
    "df_recipes['ingredients_parsed'] = df_recipes.ingredients_parsed.values.astype('U')\n",
    "\n",
    "# TF-IDF feature extractor \n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(df_recipes['ingredients_parsed'])\n",
    "tfidf_recipe = tfidf.transform(df_recipes['ingredients_parsed'])\n",
    "\n",
    "# save the tfidf model and encodings \n",
    "with open(TFIDF_MODEL_PATH, \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "with open(TFIDF_ENCODING_PATH, \"wb\") as f:\n",
    "    pickle.dump(tfidf_recipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.669\n",
      "1    0.619\n",
      "2    0.603\n",
      "3    0.578\n",
      "4    0.575\n",
      "Name: score, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic Spicy Tomato Sauce</td>\n",
       "      <td>1 (28 ounce) can crushed tomatoes,1 cup diced ...</td>\n",
       "      <td>0.669</td>\n",
       "      <td>https://www.allrecipes.com/recipe/158899/basic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mild Curry Omelet</td>\n",
       "      <td>1 tablespoon light sesame oil,1/2 teaspoon gro...</td>\n",
       "      <td>0.619</td>\n",
       "      <td>https://www.allrecipes.com/recipe/134590/mild-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sher-a-Punjab Onion Chutney</td>\n",
       "      <td>1 sweet onion (such as Vidalia(R)), minced,1 t...</td>\n",
       "      <td>0.603</td>\n",
       "      <td>https://www.allrecipes.com/recipe/237761/sher-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Curried Hash Browns</td>\n",
       "      <td>1 tablespoon butter,1 tablespoon chopped green...</td>\n",
       "      <td>0.578</td>\n",
       "      <td>https://www.allrecipes.com/recipe/163927/curri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pizza Sauce II</td>\n",
       "      <td>1 cup minced onion,1/4 cup olive oil,1/4 teasp...</td>\n",
       "      <td>0.575</td>\n",
       "      <td>https://www.allrecipes.com/recipe/25402/pizza-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         recipe  \\\n",
       "0     Basic Spicy Tomato Sauce    \n",
       "1            Mild Curry Omelet    \n",
       "2  Sher-a-Punjab Onion Chutney    \n",
       "3          Curried Hash Browns    \n",
       "4               Pizza Sauce II    \n",
       "\n",
       "                                         ingredients  score  \\\n",
       "0  1 (28 ounce) can crushed tomatoes,1 cup diced ...  0.669   \n",
       "1  1 tablespoon light sesame oil,1/2 teaspoon gro...  0.619   \n",
       "2  1 sweet onion (such as Vidalia(R)), minced,1 t...  0.603   \n",
       "3  1 tablespoon butter,1 tablespoon chopped green...  0.578   \n",
       "4  1 cup minced onion,1/4 cup olive oil,1/4 teasp...  0.575   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.allrecipes.com/recipe/158899/basic...  \n",
       "1  https://www.allrecipes.com/recipe/134590/mild-...  \n",
       "2  https://www.allrecipes.com/recipe/237761/sher-...  \n",
       "3  https://www.allrecipes.com/recipe/163927/curri...  \n",
       "4  https://www.allrecipes.com/recipe/25402/pizza-...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the system\n",
    "test_ingredients = \"red onions\"\n",
    "recs = RecSys(test_ingredients)\n",
    "print(recs.score)\n",
    "#print(recs)\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get version numbers of listed packages\n",
    "%pip list"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
